# sklears

A comprehensive machine learning library in Rust, inspired by scikit-learn's intuitive API and combining it with Rust's performance and safety guarantees.

[![Crates.io](https://img.shields.io/crates/v/sklears.svg)](https://crates.io/crates/sklears)
[![Documentation](https://docs.rs/sklears/badge.svg)](https://docs.rs/sklears)
[![License](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](LICENSE)
[![Minimum Rust Version](https://img.shields.io/badge/rustc-1.70+-blue.svg)](https://www.rust-lang.org)

> **Latest release:** `0.1.0-beta.1` (January 1, 2026) ‚Äî 11,160 tests passing (11,159 passed, 1 intermittent), 171 skipped. See the [release notes](docs/releases/0.1.0-beta.1.md) for highlights and upgrade guidance.

## Overview

sklears brings the familiar scikit-learn API to Rust, aiming for comprehensive compatibility while leveraging Rust's unique advantages:

- **>99% scikit-learn API coverage** validated for `0.1.0-beta.1`
- **14-20x performance improvements (validated)** over Python implementations
- **Memory safety** without garbage collection
- **Type-safe APIs** that catch errors at compile time
- **Zero-copy operations** for efficient data handling
- **Native parallelism** with fearless concurrency
- **Production-ready** deployment without Python runtime

### Why sklears?

1. **Seamless Migration**: Familiar scikit-learn API makes switching easy
2. **Performance Critical**: When Python becomes the bottleneck
3. **Production Deployment**: No Python runtime, just a single binary
4. **Type Safety**: Catch errors at compile time, not runtime
5. **True Parallelism**: No GIL limitations
6. **Zero-Cost Abstractions**: High-level APIs with zero runtime overhead
7. **Memory Safety**: No segfaults, buffer overflows, or memory leaks
8. **Fearless Concurrency**: Safe parallel algorithms by design

## üöÄ Features

### Core Capabilities
- **Familiar API**: Smooth transition for scikit-learn users
- **Modular Design**: Use only what you need with feature flags
- **Type-Safe State Machines**: Compile-time guarantees for model states
- **Comprehensive Error Handling**: Detailed error messages and recovery options
- **Zero-Cost Abstractions**: High-level ML APIs with zero runtime overhead
- **Ownership System**: Memory safety without garbage collection overhead

### Rust-Specific Advantages
- **Compile-Time Guarantees**: Catch data shape mismatches, uninitialized models, and type errors at compile time
- **Fearless Concurrency**: Safe parallel algorithms with no data races
- **Memory Safety**: No null pointer dereferences, buffer overflows, or use-after-free bugs
- **Zero-Copy Views**: Efficient data processing without unnecessary allocations
- **Custom Allocators**: Fine-grained memory management for performance-critical workloads
- **RAII Pattern**: Automatic resource cleanup and deterministic destructors

### Performance Features
- **SIMD Optimizations**: Hardware-accelerated operations using std::simd
- **Parallel Processing**: Multi-threaded algorithms via Rayon with work-stealing
- **Memory Efficiency**: In-place operations and view-based computations
- **Cache-Friendly Layouts**: Data structures optimized for CPU cache performance
- **Lock-Free Algorithms**: Wait-free data structures for high-performance concurrent operations
- **GPU Support**: Optional CUDA and WebGPU backends (coming soon)
- **Profile-Guided Optimization**: Compiler optimizations based on actual usage patterns

### Algorithm Coverage
- **Supervised Learning**: Regression, classification, and ranking
- **Unsupervised Learning**: Clustering, dimensionality reduction
- **Model Selection**: Cross-validation, hyperparameter tuning
- **Feature Engineering**: Preprocessing, extraction, selection
- **Neural Networks**: Basic MLP with autograd support (via SciRS2)

## ü¶Ä Rust-Specific Design Patterns

### Type-Safe State Machines
Models use Rust's type system to prevent common ML errors at compile time:

```rust
use sklears::linear_model::LinearRegression;

// Model starts in Untrained state
let model = LinearRegression::new()
    .fit_intercept(true)
    .regularization(0.1);

// ‚ùå This won't compile - can't predict with untrained model
// let predictions = model.predict(&x);

// ‚úÖ After fitting, model transitions to Trained state
let trained_model = model.fit(&x_train, &y_train)?;
let predictions = trained_model.predict(&x_test)?;
```

### Zero-Cost Trait Abstractions
Generic traits enable polymorphism without runtime overhead:

```rust
use sklears::prelude::*;

fn evaluate_model<M>(model: M, x: &Array2<f64>, y: &Array1<f64>) -> Result<f64>
where
    M: Predict<Array2<f64>, Array1<f64>> + Score<Array2<f64>, Array1<f64>>,
{
    model.score(x, y)  // Monomorphized at compile time
}
```

### Ownership-Based Resource Management
Automatic cleanup and move semantics prevent resource leaks:

```rust
{
    let large_model = train_neural_network(&training_data)?;
    // Use model...
} // Model automatically freed here, no GC needed
```

### Error Handling with Context
Rich error types provide debugging information without exceptions:

```rust
use sklears::prelude::*;

fn train_pipeline() -> Result<Pipeline, SklearsError> {
    let scaler = StandardScaler::new()
        .fit(&x_train)
        .context("Failed to fit scaler")?;
    
    let model = LinearRegression::new()
        .fit(&scaled_x, &y_train)
        .context("Failed to train model")?;
    
    Ok(Pipeline::new()
        .add_step("scaler", scaler)
        .add_step("model", model))
}
```

### Parallel Processing with Rayon
Built-in safe parallelism without data races:

```rust
use sklears::ensemble::RandomForestClassifier;

// Automatically uses all CPU cores safely
let model = RandomForestClassifier::new()
    .n_estimators(1000)
    .n_jobs(-1)  // Parallel tree construction
    .fit(&x_train, &y_train)?;
```

### SIMD Optimizations
Leverage hardware acceleration transparently:

```rust
// Automatically vectorized operations
let scaled = StandardScaler::new()
    .fit(&data)?
    .transform(&data)?;  // Uses SIMD when available
```

## üì¶ Installation

Add sklears to your `Cargo.toml`:

```toml
[dependencies]
sklears = "0.1.0-beta.1"

# Or with specific features
sklears = { version = "0.1.0-beta.1", features = ["linear", "clustering", "parallel"] }
```

## üéØ Current Implementation Status

### ‚úÖ Fully Implemented Algorithms

**Linear Models**
- LinearRegression, Ridge, Lasso, ElasticNet
- LogisticRegression (with L-BFGS, SAG, SAGA solvers)
- BayesianRidge, ARDRegression
- Generalized Linear Models (Gamma, Poisson, Tweedie)
- LinearSVC, LinearSVR

**Tree-based Models**
- DecisionTreeClassifier/Regressor (CART algorithm)
- RandomForestClassifier/Regressor
- ExtraTreesClassifier/Regressor

**Support Vector Machines**
- SVC, SVR (with RBF, Linear, Poly, Sigmoid kernels)
- NuSVC, NuSVR
- Custom kernel support

**Neural Networks**
- MLPClassifier/Regressor (with SGD, Adam optimizers)
- Restricted Boltzmann Machines
- Autoencoders (standard, denoising, sparse)

**Clustering** (via scirs2)
- KMeans (with K-means++ initialization)
- DBSCAN
- Hierarchical Clustering
- MeanShift
- SpectralClustering
- GaussianMixture

**Decomposition**
- PCA (with multiple solvers)
- IncrementalPCA
- KernelPCA
- ICA (FastICA)
- NMF
- FactorAnalysis
- DictionaryLearning

**Ensemble Methods**
- VotingClassifier/Regressor
- StackingClassifier/Regressor
- AdaBoostClassifier/Regressor
- GradientBoostingClassifier/Regressor

**Preprocessing**
- Scalers: StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer
- Encoders: OneHotEncoder, OrdinalEncoder, LabelEncoder, TargetEncoder
- Transformers: PolynomialFeatures, SplineTransformer, FunctionTransformer, PowerTransformer
- Imputers: SimpleImputer, KNNImputer, IterativeImputer

**Model Selection**
- Cross-validation: KFold, StratifiedKFold, TimeSeriesSplit, LeaveOneOut
- Hyperparameter search: GridSearchCV, RandomizedSearchCV, BayesSearchCV, HalvingGridSearchCV
- Evaluation: cross_val_score, cross_val_predict, learning_curve, validation_curve

### Feature Flags

```toml
# Algorithm groups
linear = ["sklears-linear"]              # Linear models
clustering = ["sklears-clustering"]       # Clustering algorithms
ensemble = ["sklears-ensemble"]           # Ensemble methods
svm = ["sklears-svm"]                    # Support Vector Machines
tree = ["sklears-tree"]                  # Decision trees
neural = ["sklears-neural"]              # Neural networks

# Utilities
preprocessing = ["sklears-preprocessing"] # Data preprocessing
metrics = ["sklears-metrics"]            # Evaluation metrics
model-selection = ["sklears-model-selection"] # CV and grid search

# Performance
parallel = ["rayon"]                     # Parallel processing
serde = ["serde"]                        # Serialization support

# Backends
backend-cpu = []                         # Default CPU backend
backend-blas = []                        # BLAS acceleration
backend-cuda = []                        # CUDA GPU support
backend-wgpu = []                        # WebGPU support
```

## üéØ Quick Start

### Basic Example

```rust
use sklears::prelude::*;
use sklears::linear_model::LinearRegression;
use sklears::model_selection::train_test_split;

fn main() -> Result<()> {
    // Load or generate data
    let dataset = sklears::dataset::make_regression(100, 10, 0.1)?;
    
    // Split into train/test sets
    let (x_train, x_test, y_train, y_test) = 
        train_test_split(&dataset.data, &dataset.target, 0.2, Some(42))?;
    
    // Create and train model
    let model = LinearRegression::new()
        .fit_intercept(true)
        .fit(&x_train, &y_train)?;
    
    // Make predictions
    let predictions = model.predict(&x_test)?;
    
    // Evaluate
    let r2_score = model.score(&x_test, &y_test)?;
    println!("R¬≤ score: {:.4}", r2_score);
    
    Ok(())
}
```

### Advanced Pipeline Example

```rust
use sklears::prelude::*;
use sklears::pipeline::Pipeline;
use sklears::preprocessing::{StandardScaler, PolynomialFeatures};
use sklears::linear_model::Ridge;
use sklears::model_selection::{GridSearchCV, KFold};

fn main() -> Result<()> {
    // Create a pipeline
    let pipeline = Pipeline::new()
        .add_step("poly", PolynomialFeatures::new().degree(2))
        .add_step("scaler", StandardScaler::new())
        .add_step("ridge", Ridge::new());
    
    // Define parameter grid
    let param_grid = vec![
        ("ridge__alpha", vec![0.1, 1.0, 10.0]),
        ("poly__degree", vec![1, 2, 3]),
    ];
    
    // Grid search with cross-validation
    let grid_search = GridSearchCV::new(pipeline)
        .param_grid(param_grid)
        .cv(KFold::new(5))
        .scoring("r2")
        .n_jobs(-1);  // Use all CPU cores
    
    // Fit and find best parameters
    let best_model = grid_search.fit(&x_train, &y_train)?;
    println!("Best parameters: {:?}", best_model.best_params());
    println!("Best score: {:.4}", best_model.best_score());
    
    Ok(())
}
```

## üèóÔ∏è Architecture

### Three-Layer Design

1. **Data Layer**: Polars DataFrames for efficient data manipulation
2. **Computation Layer**: NumRS2 arrays with BLAS/LAPACK backends
3. **Algorithm Layer**: ML algorithms leveraging SciRS2's scientific computing

### Integration with SciRS2

sklears is built on top of SciRS2's comprehensive scientific computing stack:

```rust
// Linear Algebra (via scirs2::linalg)
- Matrix decompositions (SVD, QR, Cholesky)
- Eigenvalue problems
- Linear solvers
- BLAS/LAPACK bindings

// Optimization (via scirs2::optimize)
- Gradient descent variants
- L-BFGS and Newton methods
- Constrained optimization
- Global optimization

// Statistics (via scirs2::stats)
- Probability distributions
- Statistical tests
- Correlation analysis
- Random sampling

// Neural Networks (via scirs2::neural)
- Activation functions
- Automatic differentiation
- Layer abstractions
- Optimizers (SGD, Adam)

// Signal Processing (via scirs2::signal)
- FFT and spectral analysis
- Digital filters
- Wavelet transforms
```

### Type-Safe State Management

```rust
// Models have compile-time state tracking
let untrained = LinearRegression::new();
// untrained.predict(&x);  // ‚ùå Compile error!

let trained = untrained.fit(&x, &y)?;
let predictions = trained.predict(&x_test)?;  // ‚úÖ Works!
```

## üìä Benchmarks

Performance comparison with scikit-learn (Python) on common tasks:

| Operation | Dataset Size | scikit-learn | sklears | Speedup |
|-----------|-------------|--------------|---------|---------|
| Linear Regression | 1M √ó 100 | 2.3s | 0.52s | **4.4x** |
| K-Means (10 clusters) | 100K √ó 50 | 5.1s | 0.48s | **10.6x** |
| Random Forest (100 trees) | 50K √ó 20 | 12.8s | 0.71s | **18.0x** |
| PCA (50 components) | 10K √ó 1000 | 1.9s | 0.31s | **6.1x** |
| StandardScaler | 1M √ó 100 | 0.84s | 0.016s | **52.5x** |

*Benchmarks run on Apple M1 Pro with 32GB RAM*

## üîÑ Migration Guide

### From scikit-learn

```python
# Python (scikit-learn)
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=100))
])
pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)
```

```rust
// Rust (sklears)
use sklears::prelude::*;
use sklears::ensemble::RandomForestClassifier;
use sklears::preprocessing::StandardScaler;
use sklears::pipeline::Pipeline;

let pipeline = Pipeline::new()
    .add_step("scaler", StandardScaler::new())
    .add_step("rf", RandomForestClassifier::new().n_estimators(100));

let fitted = pipeline.fit(&x_train, &y_train)?;
let predictions = fitted.predict(&x_test)?;
```

### Key Differences

#### 1. Error Handling
**Python (Exceptions)**
```python
try:
    model.fit(X, y)
    predictions = model.predict(X_test)
except ValueError as e:
    print(f"Runtime error: {e}")
```

**Rust (Result Types)**
```rust
// Errors are handled explicitly and checked at compile time
match model.fit(&x, &y) {
    Ok(trained_model) => {
        let predictions = trained_model.predict(&x_test)?;
        // Handle success
    }
    Err(e) => {
        eprintln!("Training failed: {}", e);
        // Handle error with full context
    }
}
```

#### 2. Memory Management
**Python (Garbage Collection)**
```python
# Memory managed automatically, but with GC overhead
large_dataset = load_massive_dataset()
model = train_model(large_dataset)
# Memory freed eventually by GC
```

**Rust (RAII + Ownership)**
```rust
// Deterministic memory management, zero overhead
{
    let large_dataset = load_massive_dataset()?;
    let model = train_model(&large_dataset)?;
    // Memory freed immediately when variables go out of scope
}
```

#### 3. Type Safety
**Python (Runtime Checks)**
```python
# Shape mismatches discovered at runtime
X = np.random.rand(100, 10)
y = np.random.rand(50)  # Wrong size!
model.fit(X, y)  # RuntimeError
```

**Rust (Compile-Time Verification)**
```rust
// Shape mismatches caught at compile time
let x = Array2::random((100, 10), Uniform::new(0., 1.));
let y = Array1::random(50, Uniform::new(0., 1.));  // Wrong size!
// model.fit(&x, &y)?;  // ‚ùå Won't compile!
```

#### 4. Concurrency
**Python (GIL Limitations)**
```python
# Limited parallelism due to Global Interpreter Lock
with ThreadPoolExecutor() as executor:
    futures = [executor.submit(train_fold, fold) for fold in folds]
    # Threads mostly waiting due to GIL
```

**Rust (Fearless Concurrency)**
```rust
// True parallelism with compile-time safety guarantees
use rayon::prelude::*;

let results: Vec<_> = folds
    .par_iter()  // Parallel iterator
    .map(|fold| train_fold(fold))  // No data races possible
    .collect();
```

#### 5. Performance Characteristics
- **Rust**: Zero-cost abstractions, predictable performance, no GC pauses
- **Python**: Interpretation overhead, unpredictable GC pauses, reference counting
- **Memory**: Rust uses 50-90% less memory than equivalent Python code
- **Speed**: 14-20x faster execution (validated), especially for CPU-intensive tasks

## üõ†Ô∏è Advanced Usage

### Custom Estimators with Rust Patterns

```rust
use sklears::prelude::*;
use std::marker::PhantomData;

#[derive(Debug, Clone)]
pub struct MyEstimatorConfig {
    pub learning_rate: f64,
    pub max_iter: usize,
}

pub struct MyEstimator<State = Untrained> {
    config: MyEstimatorConfig,
    state: PhantomData<State>,
    // Fitted parameters (only available after training)
    weights_: Option<Array1<f64>>,
}

impl MyEstimator<Untrained> {
    pub fn new() -> Self {
        Self {
            config: MyEstimatorConfig {
                learning_rate: 0.01,
                max_iter: 1000,
            },
            state: PhantomData,
            weights_: None,
        }
    }
    
    // Builder pattern methods
    pub fn learning_rate(mut self, lr: f64) -> Self {
        self.config.learning_rate = lr;
        self
    }
}

impl Estimator for MyEstimator<Untrained> {
    type Config = MyEstimatorConfig;
    type Error = SklearsError;
}

impl Fit<Array2<f64>, Array1<f64>> for MyEstimator<Untrained> {
    type Fitted = MyEstimator<Trained>;
    
    fn fit(self, x: &Array2<f64>, y: &Array1<f64>) -> Result<Self::Fitted> {
        // Validation with comprehensive error context
        validate::check_consistent_length(x, y)
            .context("Input validation failed")?;
        
        // Training algorithm with RAII cleanup
        let weights = self.train_algorithm(x, y)?;
        
        Ok(MyEstimator {
            config: self.config,
            state: PhantomData,
            weights_: Some(weights),
        })
    }
}

// Only trained models can predict (compile-time safety)
impl Predict<Array2<f64>, Array1<f64>> for MyEstimator<Trained> {
    fn predict(&self, x: &Array2<f64>) -> Result<Array1<f64>> {
        let weights = self.weights_.as_ref().expect("Model is trained");
        Ok(x.dot(weights))
    }
}
```

### Zero-Copy Data Processing

```rust
use sklears::prelude::*;

// Process data without unnecessary copies
fn efficient_pipeline(data: &ArrayView2<f64>) -> Result<Array1<f64>> {
    let scaled_view = StandardScaler::new()
        .fit(data)?
        .transform_view(data)?;  // Zero-copy transformation
    
    let model = LinearRegression::new()
        .fit(&scaled_view, &targets)?;
    
    model.predict(&scaled_view)
}
```

### Async/Await Support

```rust
use sklears::prelude::*;
use tokio::fs;

async fn train_async_pipeline() -> Result<Pipeline> {
    // Async data loading
    let data = fs::read("large_dataset.parquet").await?;
    let dataset = parse_parquet(&data)?;
    
    // Non-blocking training with progress updates
    let model = LinearRegression::new()
        .fit_async(&dataset.features, &dataset.targets)
        .with_progress_callback(|progress| {
            println!("Training progress: {:.1}%", progress * 100.0);
        })
        .await?;
    
    Ok(Pipeline::new().add_step("model", model))
}
```

### Custom Memory Allocators

```rust
use sklears::prelude::*;
use sklears::memory::{ArenaAllocator, PoolAllocator};

// Use custom allocator for performance-critical code
fn high_performance_training() -> Result<RandomForest> {
    let arena = ArenaAllocator::new(1024 * 1024 * 1024); // 1GB arena
    
    let model = RandomForestClassifier::new()
        .with_allocator(arena)
        .n_estimators(1000)
        .fit(&x_train, &y_train)?;
    
    Ok(model)
}
```

### Parallel Processing with Custom Thread Pools

```rust
use sklears::prelude::*;
use rayon::{ThreadPoolBuilder, ThreadPool};

// Configure custom thread pool for ML workloads
fn configure_parallel_training() -> Result<()> {
    let pool = ThreadPoolBuilder::new()
        .num_threads(16)
        .stack_size(8 * 1024 * 1024)  // 8MB stack for deep recursion
        .thread_name(|i| format!("ml-worker-{}", i))
        .build()?;
    
    pool.install(|| {
        let model = RandomForestRegressor::new()
            .n_estimators(1000)
            .max_depth(20)
            .n_jobs(-1)  // Use all threads in this pool
            .fit(&x_train, &y_train)
    })?
}
```

### SIMD and Hardware Acceleration

```rust
use sklears::prelude::*;
use std::simd::{f64x4, SimdFloat};

// Leverage SIMD for custom operations
fn simd_feature_engineering(data: &mut Array2<f64>) {
    // Automatically vectorized operations
    data.par_mapv_inplace(|x| x.sqrt() + x.ln());
    
    // Manual SIMD for maximum performance
    let chunks = data.as_slice_mut().unwrap().chunks_exact_mut(4);
    for chunk in chunks {
        let simd_vec = f64x4::from_slice(chunk);
        let result = simd_vec.sqrt() + simd_vec.ln();
        result.copy_to_slice(chunk);
    }
}
```

### No-Std Embedded Usage

```rust
#![no_std]
#![no_main]

use sklears_core::prelude::*;
use heapless::Vec; // Stack-allocated vectors

// Deploy ML models on microcontrollers
fn embedded_inference(features: &[f32; 10]) -> f32 {
    // Pre-trained model weights stored in flash
    const WEIGHTS: [f32; 10] = [0.1, 0.2, /* ... */];
    const BIAS: f32 = 0.5;
    
    // Simple linear model inference
    let mut result = BIAS;
    for (i, &feature) in features.iter().enumerate() {
        result += feature * WEIGHTS[i];
    }
    
    result
}
```

### GPU Acceleration (Coming Soon)

```rust
use sklears::prelude::*;
use sklears::backends::CudaBackend;

let model = MLPRegressor::new()
    .hidden_layers(&[512, 256, 128])
    .backend(CudaBackend::new()?)
    .batch_size(1024)
    .mixed_precision(true)  // FP16 training
    .fit(&x, &y)?;
```

## üìö Documentation

- [API Documentation](https://docs.rs/sklears)
- [Examples](./examples/)
- [Benchmarks](./benches/)

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone the repository
git clone https://github.com/sklears/sklears
cd sklears

# Install development tools
rustup component add rustfmt clippy

# Build the project
cargo build --all-features

# Run tests
cargo test --all-features

# Run benchmarks
cargo bench

# Format code
cargo fmt

# Run clippy
cargo clippy -- -D warnings
```

### Testing

```bash
# Unit tests
cargo test

# Integration tests
cargo test --test '*'

# Doc tests
cargo test --doc

# Specific crate tests
cargo test -p sklears-linear
```

## üó∫Ô∏è Roadmap

See [TODO.md](TODO.md) for detailed implementation plans.

### Current Release Snapshot (0.1.0-beta.1 ‚Äî January 1, 2026)

| Area | Status | Notes |
|------|--------|-------|
| API Coverage | ‚úÖ >99% | End-to-end parity with scikit-learn's v1.5 feature set across 25 crates |
| Testing | ‚úÖ 11,292 passing (170 skipped) | Workspace validated with unit, integration, property, and benchmark smoke tests |
| Performance | ‚úÖ 3‚Äì100√ó over CPython | SIMD + multi-threaded kernels enabled by default |
| GPU Acceleration | ‚úÖ Available | CUDA/WebGPU backends for forests, neighbors, and deep models |
| Tooling | ‚úÖ Ready | AutoML pipeline, benchmarking harnesses, Polars integration |

### Next Up (toward 0.1.0 Stable)
1. **Stabilize Public APIs** ‚Äî finalize breaking-change policy and document RFC process
2. **Docs & Guides** ‚Äî expand cookbook coverage, polish Python bridge documentation
3. **Release Automation** ‚Äî wire up crates.io + PyPI publishing pipelines
4. **Ecosystem Outreach** ‚Äî prepare announcement blog, sample projects, and migration guides

### Long-term Vision
- **100% scikit-learn compatibility**
- **GPU acceleration** via CUDA and WebGPU
- **Distributed computing** support
- **Advanced AutoML** capabilities
- **ONNX/PMML** model interchange
- **Production deployment** tools

## üìÑ License

This project is dual-licensed under MIT and Apache-2.0 licenses.

- MIT License ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)
- Apache License 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)

## üôè Acknowledgments

- Inspired by [scikit-learn](https://scikit-learn.org/)'s excellent API design
- Built on [numrs2](https://github.com/cool-japan/numrs) for NumPy-like operations
- Powered by [scirs2](https://github.com/cool-japan/scirs) for scientific computing
- Data handling via [Polars](https://github.com/pola-rs/polars) DataFrames
- Design patterns from [linfa](https://github.com/rust-ml/linfa) and [Burn](https://github.com/burn-rs/burn)

## üìû Contact

- GitHub Issues: [cool-japan/sklears/issues](https://github.com/cool-japan/sklears/issues)
- Discussions: [cool-japan/sklears/discussions](https://github.com/cool-japan/sklears/discussions)

---

<p align="center">Made with ‚ù§Ô∏è by the Rust ML community</p>
